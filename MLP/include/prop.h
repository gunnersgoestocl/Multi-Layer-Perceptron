#include "init.h"

# ifndef _PROP_H_
# define _PROP_H_

// 5. 関数```forward_prop```を定義する (void型)
//   - 出力の推定量を求める
//   - 説明変数値の二次元配列```x```と、目的変数値の二次元配列```y```と、ネットワーク層構造体の線形リストの先頭へのポインタ```neural_network```と、活性化関数のポインタ```activator```を引数にとり、各ニューロンの入力値```v```と出力値```o```などを更新していく
//   - 手順は、
//     - 第 $0$ ニューロン層の第 $b$ 行の入力値```v```を```x[b]```(これはミニバッチの $b$番目のデータに相当)の各要素に設定する
//       - ということを、$b$について $0<=b<b_size$ で繰り返す
//     - 第 $0$ ニューロン層の出力値```o```を更新する(この時は```v```と```o```は同じ値)
//     - 第 $D$ 層までのニューロンの入力値と出力値を交互に計算し更新する(行列の積を計算する)
//       - この時、第 $k$ 層のニューロンの入力値```v```は、第 $k-1$ 層のニューロンの出力値```o```と、第 $k$ 層の重み```weight```の行列の積として計算する
//       - 第 $k$ 層のニューロンへの入力値```v```を```activator```(leakly_relu)にかけ、第 $k$ 層のニューロンの出力値```o```を計算し更新する
//       - ```v```の更新後、活性化関数の勾配```delA```をバッチ・ニューロンごとに計算し更新する
//     - 第 $D+1$ ニューロン層への入力値```v```から第 $D+1$ ニューロン層の出力値```o```を返す(この時は```v```と```o```は同じ値でこれが出力の推定量となる)
//       - 代わりに、目的変数値のベクトル```y```を元に、第 $D+1$ ニューロン層の```delta```に、各データごと($0 <= b < b_size$)に```o```と```y```の差をとったものを代入する

network_1layer *forward_prop(double **x, double **y, network_1layer *neural_network, double (*activator)(double), double (*activator_grad)(double));

// 6. 関数```back_prop```を定義する
//    - 誤差逆伝播を行い```neural_network```を更新する
//    - 引数はネットワーク層構造体の線形リストの末尾要素へのポインタ```neural_network```と、学習率```alpha```と、バッチサイズ```b_size```
//    - まず、第 $D+1$ ニューロン層の```delta```を用いて、第 $D+1$ ネットワーク層の行列成分 $U[i][j]$ を更新する
//       - 「第 $D$ ニューロン層の```o```と第 $D+1$ ニューロン層の```delta```の積」の $0 <= b < b_size$ での平均```del_Uij```を、各i,jの組について計算する
//       - 第 $D+1$ ネットワーク層の行列成分 $U[i][j]$ は $U[i][j]-  alpha* del_Uij$ に更新される
//    - 次に、第 $D$ ニューロン層の、第 $b$ データの第 $i$ ニューロンの```delta```を更新する ($0 <= b < b_size$)
//       - 「第 $D+1$ ニューロン層の第 $l$ ニューロンの```delta```の値と、第 $D+1$ ニューロン層の行列成分 $U[l][i]$ の値の積」の $0<=l<N_{D+1}$ での和に、更新したいニューロンの```delA```を掛けたものを```delta```とする
//    - 以下同様に、ネットワーク層の行列成分の更新と、ニューロン層の各ニューロンの```delta```の更新を繰り返す
//      - 第 $1$ ネットワーク層の行列成分の更新で、全体の更新を終える
//    - 線形リストの先頭のネットワーク層構造体へのポインタを返す

network_1layer *back_prop(network_1layer *neural_network, double alpha, int b_size);

double leakly_relu(double v);
double leakly_relu_grad(double v);

# endif